{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from openai import OpenAI\n",
    "from libretranslatepy import LibreTranslateAPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing transcript json...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ensure libretranslate is running on port 5000\n",
    "\n",
    "number_return_values = 1\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"sk-proj-HSrHGyOHtEDtr9loLzRjT3BlbkFJTUFaqCLYDEs3B7qpBz7z\"))\n",
    "\n",
    "transcript_json= Path().cwd().parent.joinpath('data/output_json/transcript.json')\n",
    "\n",
    "print('Importing transcript json...')\n",
    "\n",
    "transcript_df = pd.read_json(transcript_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizing data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Organizing data...')\n",
    "\n",
    "exploded_transcript_df = transcript_df.explode('transcription').reset_index(drop=True)\n",
    "\n",
    "exploded_transcript_df = exploded_transcript_df[['file_name', 'transcription']]\n",
    "\n",
    "embedded_false_statements_path = Path().cwd().parent.joinpath('data/factchecked_statements/embedded_false_statements.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actualidad_Radio_0523_000.mp3</td>\n",
       "      <td>y y y y y y y y y y y y y y y y y cambiado de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actualidad_Radio_0523_000.mp3</td>\n",
       "      <td>De dés breakfast, de Estado, mepolisaba una de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Actualidad_Radio_0523_000.mp3</td>\n",
       "      <td>unbank a Charlotte, un ayupo,ambreodies plaño,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actualidad_Radio_0523_000.mp3</td>\n",
       "      <td>El último presidente que le fue bien en Nueva ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Actualidad_Radio_0523_000.mp3</td>\n",
       "      <td>Vamos a hablarles también de lo que está pasan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6896</th>\n",
       "      <td>América_Noticias_0524_057.mp3</td>\n",
       "      <td>¡El siguiente programa es una emisión previame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6897</th>\n",
       "      <td>América_Noticias_0524_058.mp3</td>\n",
       "      <td>de la gente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6898</th>\n",
       "      <td>América_Noticias_0524_058.mp3</td>\n",
       "      <td>En el caso de la gente que se ha dado informat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6899</th>\n",
       "      <td>América_Noticias_0524_058.mp3</td>\n",
       "      <td>Las informaciones se de Cuba a esta hora por s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6900</th>\n",
       "      <td>América_Noticias_0524_058.mp3</td>\n",
       "      <td>La gente que está en la searching y que que lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6901 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          file_name  \\\n",
       "0     Actualidad_Radio_0523_000.mp3   \n",
       "1     Actualidad_Radio_0523_000.mp3   \n",
       "2     Actualidad_Radio_0523_000.mp3   \n",
       "3     Actualidad_Radio_0523_000.mp3   \n",
       "4     Actualidad_Radio_0523_000.mp3   \n",
       "...                             ...   \n",
       "6896  América_Noticias_0524_057.mp3   \n",
       "6897  América_Noticias_0524_058.mp3   \n",
       "6898  América_Noticias_0524_058.mp3   \n",
       "6899  América_Noticias_0524_058.mp3   \n",
       "6900  América_Noticias_0524_058.mp3   \n",
       "\n",
       "                                          transcription  \n",
       "0      y y y y y y y y y y y y y y y y y cambiado de...  \n",
       "1     De dés breakfast, de Estado, mepolisaba una de...  \n",
       "2     unbank a Charlotte, un ayupo,ambreodies plaño,...  \n",
       "3     El último presidente que le fue bien en Nueva ...  \n",
       "4     Vamos a hablarles también de lo que está pasan...  \n",
       "...                                                 ...  \n",
       "6896  ¡El siguiente programa es una emisión previame...  \n",
       "6897                                        de la gente  \n",
       "6898  En el caso de la gente que se ha dado informat...  \n",
       "6899  Las informaciones se de Cuba a esta hora por s...  \n",
       "6900  La gente que está en la searching y que que lo...  \n",
       "\n",
       "[6901 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/share/virtualenvs/spanish-radio-CFjM3rNK/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexploded_transcript_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/spanish-radio-CFjM3rNK/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/spanish-radio-CFjM3rNK/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "exploded_transcript_df[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing false statements with embeddings...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Importing false statements with embeddings...\")\n",
    "\n",
    "false_text_df = pd.read_csv(embedded_false_statements_path)\n",
    "\n",
    "false_text_dict = false_text_df['statement'].to_dict()\n",
    "\n",
    "false_text_df['statement_embedding'] = false_text_df.statement_embedding.apply(eval).apply(np.array)\n",
    "\n",
    "false_text_embedding_dict = false_text_df['statement_embedding'].to_dict()\n",
    "\n",
    "false_text_df['statement'] = false_text_df['statement'].replace('\\'', '').replace('/\"', '').replace('\\\"', '').replace('.','').replace('?','').replace('!','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    # Normalize each vector to unit length\n",
    "    vec1_norm = vec1 / np.linalg.norm(vec1)\n",
    "    vec2_norm = vec2 / np.linalg.norm(vec2)\n",
    "  \n",
    "    # Calculate dot product between normalized vectors\n",
    "    similarity = np.dot(vec1_norm, vec2_norm)\n",
    "    return similarity\n",
    "\n",
    "def search_false_statements(search_terms,false_text_df=false_text_df, n=number_return_values, pprint=True):\n",
    "    radio_embedding = get_embedding(search_terms, model='text-embedding-3-small')\n",
    "    similarities = []\n",
    "    counter = 0\n",
    "    total_statements = len(false_text_embedding_dict)\n",
    "    for factcheck in sorted(false_text_embedding_dict):\n",
    "        counter += 1\n",
    "        try:\n",
    "            similarities.append(cosine_similarity(factcheck, radio_embedding))\n",
    "            print_text = f\"Generated similarity for statement {counter} of {total_statements}. [{int((counter / total_statements * 100))}%]          \"\n",
    "            print(\"\\r\", print_text, end=\"\")\n",
    "        except:\n",
    "            similarities.append('failed to generate similarity')\n",
    "            print(f\"Embedding failed for statement {counter} of {total_statements}\")\n",
    "    false_text_df['similarities'] = similarities\n",
    "    results = (\n",
    "      false_text_df.sort_values(\"similarities\", ascending=False)\n",
    "      .head(n)\n",
    "   )\n",
    "    if pprint:\n",
    "      for r in results:\n",
    "         print(r[:200])\n",
    "         print()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>statement</th>\n",
       "      <th>rating</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>days_since_publication</th>\n",
       "      <th>reformated_date</th>\n",
       "      <th>url</th>\n",
       "      <th>time_since_publication</th>\n",
       "      <th>statement_embedding</th>\n",
       "      <th>similarities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e74002af-7ca3-4071-917c-0585430d459d</td>\n",
       "      <td>{'@type': 'Organization', 'name': 'Lupa', 'url...</td>\n",
       "      <td>Benjamin Netanyahu não atendeu Lula ao telefon...</td>\n",
       "      <td>Falso</td>\n",
       "      <td>2023-10-19</td>\n",
       "      <td>226</td>\n",
       "      <td>2023-10-19</td>\n",
       "      <td>https://lupa.uol.com.br/jornalismo/2023/10/19/...</td>\n",
       "      <td>226 days, 0:00:00</td>\n",
       "      <td>[-0.022783860564231873, 0.017445528879761696, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64dc0acd-92c7-45fb-9255-2a5ff85cc2da</td>\n",
       "      <td>{'@type': 'Organization', 'name': 'Boatos.org'...</td>\n",
       "      <td>LULA APROVA O USO DE PAU DE ARARA PRA TRANSPOR...</td>\n",
       "      <td>Falso</td>\n",
       "      <td>2023-10-19</td>\n",
       "      <td>226</td>\n",
       "      <td>2023-10-19</td>\n",
       "      <td>https://www.boatos.org/politica/lula-aprovou-a...</td>\n",
       "      <td>226 days, 0:00:00</td>\n",
       "      <td>[-0.022783860564231873, 0.017445528879761696, ...</td>\n",
       "      <td>[0.007634697513986262, 0.0003454049969404672, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f52fcf6-3825-4c32-b6aa-854655e70128</td>\n",
       "      <td>{'@type': 'Organization', 'name': 'Lupa', 'url...</td>\n",
       "      <td>Líder palestino defende Israel na ONU e deixa ...</td>\n",
       "      <td>Falso</td>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>222</td>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>https://lupa.uol.com.br/jornalismo/2023/10/23/...</td>\n",
       "      <td>222 days, 0:00:00</td>\n",
       "      <td>[-0.03071289137005806, 0.02502615377306938, 0....</td>\n",
       "      <td>[0.007634697513986262, 0.0003454049969404672, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f953a13b-efbe-4963-84fa-c544738fb401</td>\n",
       "      <td>{'@type': 'Organization', 'name': 'Boatos.org'...</td>\n",
       "      <td>Após falência no Brasil, Pernambucanas se vê c...</td>\n",
       "      <td>Falso</td>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>222</td>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>https://www.boatos.org/tecnologia/pernambucana...</td>\n",
       "      <td>222 days, 0:00:00</td>\n",
       "      <td>[0.06262306869029999, -0.029643438756465912, 0...</td>\n",
       "      <td>[0.007634697513986262, 0.0003454049969404672, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64dddcbd-2444-41af-8269-de7e09d3257d</td>\n",
       "      <td>{'@type': 'Organization', 'name': 'Boatos.org'...</td>\n",
       "      <td>Líder do Hamas, com Haddad e Gleise,Aliados?vo...</td>\n",
       "      <td>Falso</td>\n",
       "      <td>2023-10-19</td>\n",
       "      <td>226</td>\n",
       "      <td>2023-10-19</td>\n",
       "      <td>https://www.boatos.org/politica/haddad-gleisi-...</td>\n",
       "      <td>226 days, 0:00:00</td>\n",
       "      <td>[-0.008113361895084381, 0.01009256113320589, 0...</td>\n",
       "      <td>[0.007634697513986262, 0.0003454049969404672, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  e74002af-7ca3-4071-917c-0585430d459d   \n",
       "1  64dc0acd-92c7-45fb-9255-2a5ff85cc2da   \n",
       "2  3f52fcf6-3825-4c32-b6aa-854655e70128   \n",
       "3  f953a13b-efbe-4963-84fa-c544738fb401   \n",
       "4  64dddcbd-2444-41af-8269-de7e09d3257d   \n",
       "\n",
       "                                              author  \\\n",
       "0  {'@type': 'Organization', 'name': 'Lupa', 'url...   \n",
       "1  {'@type': 'Organization', 'name': 'Boatos.org'...   \n",
       "2  {'@type': 'Organization', 'name': 'Lupa', 'url...   \n",
       "3  {'@type': 'Organization', 'name': 'Boatos.org'...   \n",
       "4  {'@type': 'Organization', 'name': 'Boatos.org'...   \n",
       "\n",
       "                                           statement rating datePublished  \\\n",
       "0  Benjamin Netanyahu não atendeu Lula ao telefon...  Falso    2023-10-19   \n",
       "1  LULA APROVA O USO DE PAU DE ARARA PRA TRANSPOR...  Falso    2023-10-19   \n",
       "2  Líder palestino defende Israel na ONU e deixa ...  Falso    2023-10-23   \n",
       "3  Após falência no Brasil, Pernambucanas se vê c...  Falso    2023-10-23   \n",
       "4  Líder do Hamas, com Haddad e Gleise,Aliados?vo...  Falso    2023-10-19   \n",
       "\n",
       "   days_since_publication reformated_date  \\\n",
       "0                     226      2023-10-19   \n",
       "1                     226      2023-10-19   \n",
       "2                     222      2023-10-23   \n",
       "3                     222      2023-10-23   \n",
       "4                     226      2023-10-19   \n",
       "\n",
       "                                                 url time_since_publication  \\\n",
       "0  https://lupa.uol.com.br/jornalismo/2023/10/19/...      226 days, 0:00:00   \n",
       "1  https://www.boatos.org/politica/lula-aprovou-a...      226 days, 0:00:00   \n",
       "2  https://lupa.uol.com.br/jornalismo/2023/10/23/...      222 days, 0:00:00   \n",
       "3  https://www.boatos.org/tecnologia/pernambucana...      222 days, 0:00:00   \n",
       "4  https://www.boatos.org/politica/haddad-gleisi-...      226 days, 0:00:00   \n",
       "\n",
       "                                 statement_embedding  \\\n",
       "0  [-0.022783860564231873, 0.017445528879761696, ...   \n",
       "1  [-0.022783860564231873, 0.017445528879761696, ...   \n",
       "2  [-0.03071289137005806, 0.02502615377306938, 0....   \n",
       "3  [0.06262306869029999, -0.029643438756465912, 0...   \n",
       "4  [-0.008113361895084381, 0.01009256113320589, 0...   \n",
       "\n",
       "                                        similarities  \n",
       "0  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
       "1  [0.007634697513986262, 0.0003454049969404672, ...  \n",
       "2  [0.007634697513986262, 0.0003454049969404672, ...  \n",
       "3  [0.007634697513986262, 0.0003454049969404672, ...  \n",
       "4  [0.007634697513986262, 0.0003454049969404672, ...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting search of all transcripts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30965/332365212.py:6: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  vec1_norm = vec1 / np.linalg.norm(vec1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generated similarity for statement 16655 of 16655. [100%]          "
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'match_index' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 7\u001b[0m, in \u001b[0;36msearch_all_transcripts\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43msearch_false_statements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     top_match \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mstatement\u001b[38;5;241m.\u001b[39mvalues\n",
      "Cell \u001b[0;32mIn[54], line 29\u001b[0m, in \u001b[0;36msearch_false_statements\u001b[0;34m(search_terms, false_text_df, n, pprint)\u001b[0m\n\u001b[1;32m     27\u001b[0m  false_text_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarities\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m similarities\n\u001b[1;32m     28\u001b[0m  results \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 29\u001b[0m    \u001b[43mfalse_text_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimilarities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m    \u001b[38;5;241m.\u001b[39mhead(n)\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m  \u001b[38;5;28;01mif\u001b[39;00m pprint:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/spanish-radio-CFjM3rNK/lib/python3.11/site-packages/pandas/core/frame.py:7200\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7198\u001b[0m         ascending \u001b[38;5;241m=\u001b[39m ascending[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 7200\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[43mnargsort\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\n\u001b[1;32m   7202\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/spanish-radio-CFjM3rNK/lib/python3.11/site-packages/pandas/core/sorting.py:439\u001b[0m, in \u001b[0;36mnargsort\u001b[0;34m(items, kind, ascending, na_position, key, mask)\u001b[0m\n\u001b[1;32m    438\u001b[0m     non_nan_idx \u001b[38;5;241m=\u001b[39m non_nan_idx[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 439\u001b[0m indexer \u001b[38;5;241m=\u001b[39m non_nan_idx[\u001b[43mnon_nans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ascending:\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished checking all statements with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merrors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m error(s)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting search of all transcripts...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43msearch_all_transcripts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 22\u001b[0m, in \u001b[0;36msearch_all_transcripts\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m         errors \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError checking statement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmatch_index\u001b[49m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished checking all statements with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merrors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m error(s)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'match_index' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "\n",
    "top_matches_json = []\n",
    "\n",
    "def search_all_transcripts():\n",
    "    errors = 0\n",
    "    for row in exploded_transcript_df.itertuples(name='segment'):\n",
    "        try:\n",
    "            results = search_false_statements(row.transcription, pprint=False)\n",
    "            top_match = results.statement.values\n",
    "            similarity = results.similarities\n",
    "            match_index = row.Index\n",
    "            top_matches = {}\n",
    "            top_matches[\"index\"] = f\"{match_index}\"\n",
    "            top_matches[\"filename\"] = row.file_name\n",
    "            top_matches[\"input_statement\"] = row.transcription\n",
    "            top_matches[\"checked_false_statement\"] = f\"{top_match}\"\n",
    "            top_matches[\"similarity\"] = f\"{similarity}\"\n",
    "            top_matches_json.append(top_matches)\n",
    "            print_text = f\"Finished checking {match_index + 1} of {len(exploded_transcript_df)} statements -- {int((match_index + 1)/len(exploded_transcript_df)*100)}% complete         \"\n",
    "            print(\"\\r\", print_text, end=\"\")\n",
    "        except:\n",
    "            errors += 1\n",
    "            print(f\"Error checking statement {match_index + 2}\")\n",
    "    print(f\"Finished checking all statements with {errors} error(s)\")\n",
    "\n",
    "print(\"Starting search of all transcripts...\")\n",
    "\n",
    "search_all_transcripts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    # Normalize each vector to unit length\n",
    "    vec1_norm = vec1 / np.linalg.norm(vec1)\n",
    "    vec2_norm = vec2 / np.linalg.norm(vec2)\n",
    "  \n",
    "    # Calculate dot product between normalized vectors\n",
    "    similarity = np.dot(vec1_norm, vec2_norm)\n",
    "    return similarity\n",
    "\n",
    "def search_false_statements(search_terms,false_text_df=false_text_df, n=number_return_values, pprint=True):\n",
    "   embedding = get_embedding(search_terms, model='text-embedding-3-small')\n",
    "   false_text_df['similarities'] = false_text_df.statement_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "   results = (\n",
    "      false_text_df.sort_values(\"similarities\", ascending=False)\n",
    "      .head(n)\n",
    "   )\n",
    "   if pprint:\n",
    "      for r in results:\n",
    "         print(r[:200])\n",
    "         print()\n",
    "   return results\n",
    "\n",
    "top_matches_json = []\n",
    "\n",
    "def search_all_transcripts():\n",
    "    errors = 0\n",
    "    for row in exploded_transcript_df.itertuples(name='segment'):\n",
    "        try:\n",
    "            results = search_false_statements(row.transcription, pprint=False)\n",
    "            top_match = results.statement.values\n",
    "            similarity = results.similarities\n",
    "            match_index = row.Index\n",
    "            top_matches = {}\n",
    "            top_matches[\"index\"] = f\"{match_index}\"\n",
    "            top_matches[\"filename\"] = row.file_name\n",
    "            top_matches[\"input_statement\"] = row.transcription\n",
    "            top_matches[\"checked_false_statement\"] = f\"{top_match}\"\n",
    "            top_matches[\"similarity\"] = f\"{similarity}\"\n",
    "            top_matches_json.append(top_matches)\n",
    "            print_text = f\"Finished checking {match_index + 1} of {len(exploded_transcript_df)} statements -- {int((match_index + 1)/len(exploded_transcript_df)*100)}% complete         \"\n",
    "            print(\"\\r\", print_text, end=\"\")\n",
    "        except:\n",
    "            errors += 1\n",
    "            print(f\"Error checking statement {match_index + 2}\")\n",
    "    print(f\"Finished checking all statements with {errors} error(s)\")\n",
    "\n",
    "print(\"Starting search of all transcripts...\")\n",
    "\n",
    "search_all_transcripts()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Creating DataFrame...\")\n",
    "\n",
    "top_matches_df = pd.DataFrame(top_matches_json)\n",
    "\n",
    "top_matches_df.sort_values('similarity', ascending=False)\n",
    "\n",
    "lt = LibreTranslateAPI(\"http://localhost:5000\")\n",
    "\n",
    "def libretranslate_spanish(input_text):\n",
    "    return lt.translate(f\"{input_text}\", \"es\", \"en\")\n",
    "\n",
    "def libretranslate_french(input_text):\n",
    "    return lt.translate(f\"{input_text}\", \"fr\", \"en\")\n",
    "\n",
    "print(\"Adding translation...\")\n",
    "\n",
    "top_matches_df['similarity_value'] = top_matches_df['similarity'].apply(lambda x: x.split()[1]).astype(float)\n",
    "top_matches_df['factcheck_index'] = top_matches_df['similarity'].apply(lambda x: x.split()[0])\n",
    "\n",
    "over_50 = top_matches_df.loc[top_matches_df['similarity_value'] >= .50]\n",
    "\n",
    "over_50['translation'] = over_50['input_statement'].apply(lambda x: libretranslate_french(x))\n",
    "over_50['translation'] = over_50['translation'].apply(lambda x: libretranslate_spanish(x))\n",
    "\n",
    "over_50 = over_50.sort_values('similarity_value', ascending=False)\n",
    "\n",
    "over_50 = over_50[['filename', 'input_statement', 'translation', 'checked_false_statement', 'similarity_value', 'factcheck_index']]\n",
    "\n",
    "over_50_csv_filepath = Path().cwd().parent.joinpath('data/output_csv/potential_misinformation.csv')\n",
    "\n",
    "print(\"Generating csv file...\")\n",
    "\n",
    "over_50.to_csv(f\"{over_50_csv_filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spanish-radio-CFjM3rNK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
